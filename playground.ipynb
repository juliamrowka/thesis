{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'web_app\\\\documents\\\\user_1\\\\Zeszyt2.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m header_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      2\u001b[0m cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA:B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m wb \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweb_app\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43muser_1\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mZeszyt2.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(wb)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(wb))\n",
      "File \u001b[1;32mc:\\.STUDIA\\thesis\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n",
      "File \u001b[1;32mc:\\.STUDIA\\thesis\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1563\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1563\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1570\u001b[0m         )\n",
      "File \u001b[1;32mc:\\.STUDIA\\thesis\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1419\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1417\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1419\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1421\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1422\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1423\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\.STUDIA\\thesis\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'web_app\\\\documents\\\\user_1\\\\Zeszyt2.xlsx'"
     ]
    }
   ],
   "source": [
    "header_column = 0\n",
    "cols = \"A:B\"\n",
    "\n",
    "wb = pd.read_excel('web_app\\\\documents\\\\user_1\\\\Zeszyt2.xlsx', header=header_column, usecols=cols)\n",
    "print(wb)\n",
    "print(type(wb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wb = load_workbook(filename = 'web_app\\\\documents\\\\user_1\\\\iris2.xlsx')\n",
    "# ws = wb.active\n",
    "# # print(wb.path)\n",
    "# print(ws)\n",
    "# df = pd.DataFrame(ws.values)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.67332005, -0.38913705],\n",
       "       [-1.55379719, -0.39009837],\n",
       "       [-1.43427433, -0.33241898],\n",
       "       [-1.31475147, -0.37952382],\n",
       "       [-1.19522861, -0.3458775 ],\n",
       "       [-1.07570575, -0.08151359],\n",
       "       [-0.95618289, -0.3747172 ],\n",
       "       [-0.83666003, -0.36125868],\n",
       "       [-0.71713717, -0.33145765],\n",
       "       [-0.5976143 , -0.38336911],\n",
       "       [-0.47809144, -0.36125868],\n",
       "       [-0.35856858,  0.13478416],\n",
       "       [-0.23904572,  4.57032998],\n",
       "       [-0.11952286, -0.38336911],\n",
       "       [ 0.        ,  1.67770809],\n",
       "       [ 0.11952286, -0.39394367],\n",
       "       [ 0.23904572,  1.19704643],\n",
       "       [ 0.35856858, -0.33626427],\n",
       "       [ 0.47809144, -0.38433044],\n",
       "       [ 0.5976143 , -0.39394367],\n",
       "       [ 0.71713717, -0.30934722],\n",
       "       [ 0.83666003, -0.39394367],\n",
       "       [ 0.95618289,  0.86731253],\n",
       "       [ 1.07570575, -0.39394367],\n",
       "       [ 1.19522861, -0.36510397],\n",
       "       [ 1.31475147, -0.19110445],\n",
       "       [ 1.43427433, -0.38433044],\n",
       "       [ 1.55379719, -0.39394367],\n",
       "       [ 1.67332005, -0.39298234]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct= ColumnTransformer([('std',StandardScaler(),[0]), ('std2',StandardScaler(),[1])], remainder=\"passthrough\")\n",
    "\n",
    "ct.fit(wb)\n",
    "res_ct=ct.transform(wb)\n",
    "\n",
    "res_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LinearRegression.fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linear_model\n\u001b[0;32m      2\u001b[0m reg \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLinearRegression()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m reg\u001b[38;5;241m.\u001b[39mcoef_\n",
      "File \u001b[1;32mc:\\.STUDIA\\thesis\\.venv\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: LinearRegression.fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "X_train,X_test,y_train,y_test=train_test_split(iris.data,iris.target,test_size=0.2,random_state=0)\n",
    "\n",
    "pipe4=Pipeline([('std',StandardScaler()),('pca',PCA(n_components=4)),('tree',DecisionTreeClassifier())])\n",
    "\n",
    "pipe4.fit(X_train,y_train)\n",
    "res=pipe4.predict(X_train)\n",
    "np.transpose(np.array([y_train,res]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.33333333])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81649658, 0.81649658, 1.24721913])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_scaled = scaler.transform(X_train)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "X = [[ 1,  2,  3],  # 2 samples, 3 features\n",
    "     [11, 12, 13]]\n",
    "y = [0, 1]  # classes of each sample\n",
    "clf.fit(X, y)\n",
    "clf.predict(X)  # predict classes of the training data\n",
    "clf.predict([[4, 5, 6], [14, 15, 16]])  # predict classes of new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': ['Cristiano Ronaldo', 'Lionel Messi', 'Eden Hazard', 'Luis Suarez', 'Neymar'], 'Club': ['Manchester United', 'PSG', 'Real Madrid', 'Atletico Madrid', 'PSG']}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "athletes = {\n",
    "    \"Name\": [\"Cristiano Ronaldo\", \"Lionel Messi\", \"Eden Hazard\", \"Luis Suarez\", \"Neymar\"],\n",
    "    \"Club\": [\"Manchester United\", \"PSG\", \"Real Madrid\", \"Atletico Madrid\", \"PSG\"]\n",
    " }\n",
    "\n",
    "print(athletes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athletes_file = open('athletes.txt', 'wb')\n",
    "pickle.dump(athletes, athletes_file)\n",
    "athletes_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': ['Cristiano Ronaldo', 'Lionel Messi', 'Eden Hazard', 'Luis Suarez', 'Neymar'], 'Club': ['Manchester United', 'PSG', 'Real Madrid', 'Atletico Madrid', 'PSG']}\n"
     ]
    }
   ],
   "source": [
    "athletes_file = open(\"athletes.txt\", \"rb\")\n",
    "athletes = pickle.load(athletes_file)\n",
    "athletes_file.close()\n",
    "print(athletes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List my_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'StandardScaler': StandardScaler(), 'MinMaxScaler': MinMaxScaler()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe: [['std', 'StandardScaler', [0]], ['minmax', 'MinMaxScaler', [1]], ['minmax', 'MinMaxScaler', [0]]]\n",
      "True\n",
      "3\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "my_pipeline = list()\n",
    "my_pipeline.append(['std','StandardScaler',[0]])\n",
    "my_pipeline.append(['minmax','MinMaxScaler',[1]])\n",
    "my_pipeline.append(['minmax','MinMaxScaler',[0]])\n",
    "\n",
    "pipe = my_pipeline.copy()\n",
    "print(f'Pipe: {pipe}')\n",
    "print('StandardScaler' in pipe[0])\n",
    "# print(len(pipe))\n",
    "# pipe[0] = tuple(pipe[0])\n",
    "print(len(pipe))\n",
    "print(type(pipe[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "[('std', StandardScaler(), [0]), ('minmax', MinMaxScaler(), [1]), ('minmax', MinMaxScaler(), [0])]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pipe)):\n",
    "    print(i)\n",
    "    if 'StandardScaler' in pipe[i]:\n",
    "        n_index = pipe[i].index('StandardScaler')\n",
    "        # print(f'n_index: {n_index}')\n",
    "        std = my_dict['StandardScaler']\n",
    "        # print(f'std: {std}')\n",
    "        pipe[i][n_index] = my_dict['StandardScaler']\n",
    "        # print(pipe)\n",
    "        pipe[i] = tuple(pipe[i])\n",
    "    elif 'MinMaxScaler' in pipe[i]:\n",
    "        n_index = pipe[i].index('MinMaxScaler')\n",
    "        # print(f'n_index: {n_index}')\n",
    "        std = my_dict['MinMaxScaler']\n",
    "        # print(f'std: {std}')\n",
    "        pipe[i][n_index] = my_dict['MinMaxScaler']\n",
    "        # print(pipe)\n",
    "        pipe[i] = tuple(pipe[i])\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "X_test.shape, y_test.shape\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrukcja wykorzystania modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   2]\n",
      " [  2   6]\n",
      " [  3  10]\n",
      " [  4  14]\n",
      " [  5  18]\n",
      " [  6  22]\n",
      " [  7  26]\n",
      " [  8  30]\n",
      " [  9  34]\n",
      " [ 10  38]\n",
      " [ 11  42]\n",
      " [ 12  46]\n",
      " [ 13  50]\n",
      " [ 14  54]\n",
      " [ 15  58]\n",
      " [ 16  62]\n",
      " [ 17  66]\n",
      " [ 18  70]\n",
      " [ 19  74]\n",
      " [ 20  78]\n",
      " [ 21  82]\n",
      " [ 22  86]\n",
      " [ 23  90]\n",
      " [ 24  94]\n",
      " [ 25  98]\n",
      " [ 26 102]\n",
      " [ 27 106]\n",
      " [ 28 110]\n",
      " [ 29 114]\n",
      " [ 30 118]\n",
      " [ 31 122]\n",
      " [ 32 126]\n",
      " [ 33 130]\n",
      " [ 34 134]\n",
      " [ 35 138]\n",
      " [ 36 142]\n",
      " [ 37 146]\n",
      " [ 38 150]\n",
      " [ 39 154]\n",
      " [ 40 158]\n",
      " [ 41 162]\n",
      " [ 42 166]\n",
      " [ 43 170]\n",
      " [ 44 174]\n",
      " [ 45 178]\n",
      " [ 46 182]\n",
      " [ 47 186]\n",
      " [ 48 190]\n",
      " [ 49 194]\n",
      " [ 50 198]\n",
      " [ 51 202]\n",
      " [ 52 206]\n",
      " [ 53 210]\n",
      " [ 54 214]\n",
      " [ 55 218]\n",
      " [ 56 222]\n",
      " [ 57 226]\n",
      " [ 58 230]\n",
      " [ 59 234]\n",
      " [ 60 238]\n",
      " [ 61 242]\n",
      " [ 62 246]\n",
      " [ 63 250]\n",
      " [ 64 254]\n",
      " [ 65 258]\n",
      " [ 66 262]\n",
      " [ 67 266]\n",
      " [ 68 270]\n",
      " [ 69 274]\n",
      " [ 70 278]\n",
      " [ 71 282]\n",
      " [ 72 286]\n",
      " [ 73 290]\n",
      " [ 74 294]\n",
      " [ 75 298]\n",
      " [ 76 302]\n",
      " [ 77 306]\n",
      " [ 78 310]\n",
      " [ 79 314]\n",
      " [ 80 318]\n",
      " [ 81 322]\n",
      " [ 82 326]\n",
      " [ 83 330]\n",
      " [ 84 334]\n",
      " [ 85 338]\n",
      " [ 86 342]\n",
      " [ 87 346]\n",
      " [ 88 350]\n",
      " [ 89 354]\n",
      " [ 90 358]\n",
      " [ 91 362]\n",
      " [ 92 366]\n",
      " [ 93 370]\n",
      " [ 94 374]\n",
      " [ 95 378]\n",
      " [ 96 382]\n",
      " [ 97 386]\n",
      " [ 98 390]\n",
      " [ 99 394]\n",
      " [100 398]\n",
      " [101 402]\n",
      " [102 406]\n",
      " [103 410]\n",
      " [104 414]\n",
      " [105 418]\n",
      " [106 422]\n",
      " [107 426]\n",
      " [108 430]\n",
      " [109 434]\n",
      " [110 438]\n",
      " [111 442]\n",
      " [112 446]\n",
      " [113 450]\n",
      " [114 454]\n",
      " [115 458]\n",
      " [116 462]\n",
      " [117 466]\n",
      " [118 470]\n",
      " [119 474]\n",
      " [120 478]\n",
      " [121 482]\n",
      " [122 486]\n",
      " [123 490]\n",
      " [124 494]\n",
      " [125 498]\n",
      " [126 502]\n",
      " [127 506]\n",
      " [128 510]\n",
      " [129 514]\n",
      " [130 518]\n",
      " [131 522]\n",
      " [132 526]\n",
      " [133 530]\n",
      " [134 534]\n",
      " [135 538]\n",
      " [136 542]\n",
      " [137 546]\n",
      " [138 550]\n",
      " [139 554]\n",
      " [140 558]\n",
      " [141 562]\n",
      " [142 566]\n",
      " [143 570]\n",
      " [144 574]\n",
      " [145 578]\n",
      " [146 582]\n",
      " [147 586]\n",
      " [148 590]\n",
      " [149 594]\n",
      " [150 598]\n",
      " [151 602]\n",
      " [152 606]\n",
      " [153 610]\n",
      " [154 614]\n",
      " [155 618]\n",
      " [156 622]\n",
      " [157 626]\n",
      " [158 630]\n",
      " [159 634]\n",
      " [160 638]\n",
      " [161 642]\n",
      " [162 646]\n",
      " [163 650]\n",
      " [164 654]\n",
      " [165 658]\n",
      " [166 662]\n",
      " [167 666]\n",
      " [168 670]\n",
      " [169 674]\n",
      " [170 678]\n",
      " [171 682]\n",
      " [172 686]\n",
      " [173 690]\n",
      " [174 694]\n",
      " [175 698]\n",
      " [176 702]\n",
      " [177 706]\n",
      " [178 710]\n",
      " [179 714]\n",
      " [180 718]\n",
      " [181 722]\n",
      " [182 726]\n",
      " [183 730]\n",
      " [184 734]\n",
      " [185 738]\n",
      " [186 742]\n",
      " [187 746]\n",
      " [188 750]\n",
      " [189 754]\n",
      " [190 758]\n",
      " [191 762]\n",
      " [192 766]\n",
      " [193 770]\n",
      " [194 774]\n",
      " [195 778]\n",
      " [196 782]\n",
      " [197 786]\n",
      " [198 790]\n",
      " [199 794]\n",
      " [200 798]]\n",
      "root mean squared error :  0.9898860367861628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\.STUDIA\\thesis\\.venv\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# zaimportuj potrzebne paczki\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "\n",
    "# zaimportuj zbiór danych dla których chcesz zastosować model\n",
    "dataset = pd.read_excel('web_app//documents//user_1//data//linear2.xlsx') \n",
    "\n",
    "X = dataset.iloc[:, : -1].values \n",
    "Y = dataset.iloc[:, -1].values \n",
    "\n",
    "print(X)\n",
    "\n",
    "# załaduj model\n",
    "with open('web_app//documents//user_1//models//linear_model_test.pickle', 'rb') as f:\n",
    "    load_model = pickle.load(f)\n",
    "\n",
    "y_pred = load_model.predict(X)\n",
    "print('root mean squared error : ', metrics.r2_score(Y, y_pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_c = [1, 2]\n",
    "\n",
    "[x for x in range(len(max_c))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
